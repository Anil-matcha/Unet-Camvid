{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anil1331/Unet-Camvid/blob/master/Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VRVCdZX3lUgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27379cd5-903c-4d2f-9cf7-6b4e5b0b1895"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jtbGn3Wn-qFx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp CamVid.zip /content/drive/'My Drive'/\n",
        "!cp /content/drive/'My Drive'/CamVid.zip .\n",
        "!unzip -qq CamVid.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OrGgSUm6l_PP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "\n",
        "IMG_SIZE = 512\n",
        "\n",
        "def unet(pretrained_weights=None, input_size=(IMG_SIZE, IMG_SIZE, 3),num_class=2):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(drop5))\n",
        "\n",
        "    merge6 = concatenate([drop4, up6], axis=3)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = concatenate([conv3, up7], axis=3)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = concatenate([conv2, up8], axis=3)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
        "        UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = concatenate([conv1, up9], axis=3)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(num_class, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    if num_class == 2:\n",
        "        conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "        loss_function = 'binary_crossentropy'\n",
        "    else:\n",
        "        conv10 = Conv2D(num_class, 1, activation='softmax')(conv9)\n",
        "        loss_function = 'categorical_crossentropy'\n",
        "    model = Model(input=inputs, output=conv10)\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss=loss_function, metrics=[\"accuracy\"])\n",
        "    model.summary()\n",
        "\n",
        "    if (pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3_EukOomJs3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1567
        },
        "outputId": "dd481866-76b6-4d08-c05a-19f08fe74249"
      },
      "cell_type": "code",
      "source": [
        "model = unet()\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 256, 256, 64) 640         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 128, 128, 128 147584      conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 512)  0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 1024) 0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 1024) 0           dropout_3[0][0]                  \n",
            "                                                                 conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 64, 64, 512)  0           conv2d_30[0][0]                  \n",
            "                                                                 conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 128, 128, 256 0           conv2d_28[0][0]                  \n",
            "                                                                 conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 128, 128, 128 295040      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 128, 128, 128 147584      conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 256, 256, 128 0           conv2d_26[0][0]                  \n",
            "                                                                 conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 256, 256, 1)  3           conv2d_47[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,685\n",
            "Trainable params: 31,031,685\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y12NVmPMmMI3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b775382b-f5a9-4012-a6f5-76f23b6e190b"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zhixuhao/unet.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unet'...\n",
            "remote: Enumerating objects: 394, done.\u001b[K\n",
            "remote: Total 394 (delta 0), reused 0 (delta 0), pack-reused 394\u001b[K\n",
            "Receiving objects: 100% (394/394), 44.91 MiB | 54.36 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p1vN_OOWpsSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "import numpy as np\n",
        "import os\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "BackGround = [255, 255, 255]\n",
        "road = [0, 0, 0]\n",
        "# COLOR_DICT = np.array([BackGround, road])\n",
        "one = [128, 128, 128]\n",
        "two = [128, 0, 0]\n",
        "three = [192, 192, 128]\n",
        "four = [255, 69, 0]\n",
        "five = [128, 64, 128]\n",
        "six = [60, 40, 222]\n",
        "seven = [128, 128, 0]\n",
        "eight = [192, 128, 128]\n",
        "nine = [64, 64, 128]\n",
        "ten = [64, 0, 128]\n",
        "eleven = [64, 64, 0]\n",
        "twelve = [0, 128, 192]\n",
        "COLOR_DICT = np.array([one, two,three,four,five,six,seven,eight,nine,ten,eleven,twelve])\n",
        "\n",
        "\n",
        "class data_preprocess:\n",
        "    def __init__(self, train_path=None, image_folder=None, label_folder=None,\n",
        "                 valid_path=None,valid_image_folder =None,valid_label_folder = None,\n",
        "                 test_path=None, save_path=None,\n",
        "                 img_rows=512, img_cols=512,\n",
        "                 flag_multi_class=False,\n",
        "                 num_classes = 2):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.train_path = train_path\n",
        "        self.image_folder = image_folder\n",
        "        self.label_folder = label_folder\n",
        "        self.valid_path = valid_path\n",
        "        self.valid_image_folder = valid_image_folder\n",
        "        self.valid_label_folder = valid_label_folder\n",
        "        self.test_path = test_path\n",
        "        self.save_path = save_path\n",
        "        self.data_gen_args = dict(rotation_range=0.2,\n",
        "                                  width_shift_range=0.05,\n",
        "                                  height_shift_range=0.05,\n",
        "                                  shear_range=0.05,\n",
        "                                  zoom_range=0.05,\n",
        "                                  vertical_flip=True,\n",
        "                                  horizontal_flip=True,\n",
        "                                  fill_mode='nearest')\n",
        "        self.image_color_mode = \"rgb\"\n",
        "        self.label_color_mode = \"rgb\"\n",
        "\n",
        "        self.flag_multi_class = flag_multi_class\n",
        "        self.num_class = num_classes\n",
        "        self.target_size = (512, 512)\n",
        "        self.img_type = 'png'\n",
        "\n",
        "    def adjustData(self, img, label):\n",
        "        if (self.flag_multi_class):\n",
        "            img = img / 255.\n",
        "            label = label[:, :, :, 0] if (len(label.shape) == 4) else label[:, :, 0]\n",
        "            new_label = np.zeros(label.shape + (self.num_class,))\n",
        "            for i in range(self.num_class):\n",
        "                new_label[label == i, i] = 1\n",
        "            label = new_label\n",
        "        elif (np.max(img) > 1):\n",
        "            img = img / 255.\n",
        "            label = label / 255.\n",
        "            label[label > 0.5] = 1\n",
        "            label[label <= 0.5] = 0\n",
        "        return (img, label)\n",
        "\n",
        "    def trainGenerator(self, batch_size, image_save_prefix=\"image\", label_save_prefix=\"label\",\n",
        "                       save_to_dir=None, seed=7):\n",
        "        '''\n",
        "        can generate image and label at the same time\n",
        "        use the same seed for image_datagen and label_datagen to ensure the transformation for image and label is the same\n",
        "        if you want to visualize the results of generator, set save_to_dir = \"your path\"\n",
        "        '''\n",
        "        image_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        label_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=image_save_prefix,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.train_path,\n",
        "            classes=[self.label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            save_to_dir=save_to_dir,\n",
        "            save_prefix=label_save_prefix,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "\n",
        "    def testGenerator(self):\n",
        "        filenames = os.listdir(self.test_path)\n",
        "        for filename in filenames:\n",
        "            img = io.imread(os.path.join(self.test_path, filename), as_gray=False)\n",
        "            img = img / 255.\n",
        "            img = trans.resize(img, self.target_size, mode='constant')\n",
        "            img = np.reshape(img, img.shape + (1,)) if (not self.flag_multi_class) else img\n",
        "            img = np.reshape(img, (1,) + img.shape)\n",
        "            yield img\n",
        "\n",
        "    def validLoad(self, batch_size,seed=7):\n",
        "        image_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        label_datagen = ImageDataGenerator(**self.data_gen_args)\n",
        "        image_generator = image_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_image_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.image_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        label_generator = label_datagen.flow_from_directory(\n",
        "            self.valid_path,\n",
        "            classes=[self.valid_label_folder],\n",
        "            class_mode=None,\n",
        "            color_mode=self.label_color_mode,\n",
        "            target_size=self.target_size,\n",
        "            batch_size=batch_size,\n",
        "            seed=seed)\n",
        "        train_generator = zip(image_generator, label_generator)\n",
        "        for (img, label) in train_generator:\n",
        "            img, label = self.adjustData(img, label)\n",
        "            yield (img, label)\n",
        "        # return imgs,labels\n",
        "\n",
        "    def saveResult(self, npyfile, size, name,threshold=127):\n",
        "        for i, item in enumerate(npyfile):\n",
        "            img = item\n",
        "            img_std = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "            if self.flag_multi_class:\n",
        "                for row in range(len(img)):\n",
        "                    for col in range(len(img[row])):\n",
        "                        num = np.argmax(img[row][col])\n",
        "                        img_std[row][col] = COLOR_DICT[num]\n",
        "            else:\n",
        "                for k in range(len(img)):\n",
        "                    for j in range(len(img[k])):\n",
        "                        num = img[k][j]\n",
        "                        if num < (threshold/255.0):\n",
        "                            img_std[k][j] = road\n",
        "                        else:\n",
        "                            img_std[k][j] = BackGround\n",
        "            img_std = cv2.resize(img_std, size, interpolation=cv2.INTER_CUBIC)\n",
        "            cv2.imwrite(os.path.join(self.save_path, (\"%s_predict.\" + self.img_type) % (name)), img_std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MltrN4PxqTOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2465
        },
        "outputId": "7dda6b14-82da-4bd0-e654-17333e3483fa"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "!mkdir model\n",
        "!mkdir log\n",
        "train_path = \"CamVid\"\n",
        "image_folder = \"train\"\n",
        "label_folder = \"trainannot\"\n",
        "valid_path =  \"CamVid\"\n",
        "valid_image_folder =\"val\"\n",
        "valid_label_folder = \"valannot\"\n",
        "log_filepath = './log'\n",
        "flag_multi_class = True\n",
        "num_classes = 12\n",
        "dp = data_preprocess(train_path=train_path,image_folder=image_folder,label_folder=label_folder,\n",
        "                     valid_path=valid_path,valid_image_folder=valid_image_folder,valid_label_folder=valid_label_folder,\n",
        "                     flag_multi_class=flag_multi_class,\n",
        "                     num_classes=num_classes)\n",
        "\n",
        "# train your own model\n",
        "train_data = dp.trainGenerator(batch_size=2)\n",
        "valid_data = dp.validLoad(batch_size=2)\n",
        "test_data = dp.testGenerator()\n",
        "model = unet(num_class=num_classes)\n",
        "\n",
        "tb_cb = TensorBoard(log_dir=log_filepath)\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint('./model/CamVid_model_v1.hdf5', monitor='val_loss',verbose=1,save_best_only=True)\n",
        "history = model.fit_generator(train_data,\n",
        "                              steps_per_epoch=200,epochs=30,\n",
        "                              validation_steps=10,\n",
        "                              validation_data=valid_data,\n",
        "                              callbacks=[model_checkpoint,tb_cb])\n",
        "\n",
        "# draw the loss and accuracy curve\n",
        "plt.figure(12, figsize=(6, 6), dpi=60)\n",
        "plt.subplot(211)\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.title('loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(history.history['acc'], label='train')\n",
        "plt.plot(history.history['val_acc'], label='val')\n",
        "plt.title('acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘log’: File exists\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 512, 512, 64) 1792        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 512, 512, 64) 36928       conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling2D) (None, 256, 256, 64) 0           conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 256, 256, 128 73856       max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 256, 256, 128 147584      conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling2D) (None, 128, 128, 128 0           conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 128, 128, 256 295168      max_pooling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 128, 128, 256 590080      conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling2D) (None, 64, 64, 256)  0           conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 64, 64, 512)  1180160     max_pooling2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 64, 64, 512)  2359808     conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 64, 64, 512)  0           conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling2D) (None, 32, 32, 512)  0           dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 32, 32, 1024) 4719616     max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 32, 32, 1024) 9438208     conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 1024) 0           conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_29 (UpSampling2D) (None, 64, 64, 1024) 0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 64, 64, 512)  2097664     up_sampling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 64, 64, 1024) 0           dropout_15[0][0]                 \n",
            "                                                                 conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 64, 64, 512)  4719104     concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 64, 64, 512)  2359808     conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_30 (UpSampling2D) (None, 128, 128, 512 0           conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 128, 128, 256 524544      up_sampling2d_30[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 128, 128, 512 0           conv2d_174[0][0]                 \n",
            "                                                                 conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 128, 128, 256 1179904     concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 128, 128, 256 590080      conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_31 (UpSampling2D) (None, 256, 256, 256 0           conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 256, 256, 128 131200      up_sampling2d_31[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 256, 256, 256 0           conv2d_172[0][0]                 \n",
            "                                                                 conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 256, 256, 128 295040      concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 256, 256, 128 147584      conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_32 (UpSampling2D) (None, 512, 512, 128 0           conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 512, 512, 64) 32832       up_sampling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 512, 512, 128 0           conv2d_170[0][0]                 \n",
            "                                                                 conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 512, 512, 64) 73792       concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 512, 512, 64) 36928       conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 512, 512, 12) 6924        conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 512, 512, 12) 156         conv2d_191[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 31,038,760\n",
            "Trainable params: 31,038,760\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "Found 101 images belonging to 1 classes.\n",
            "Found 367 images belonging to 1 classes.\n",
            "Found 101 images belonging to 1 classes.\n",
            "Found 367 images belonging to 1 classes.\n",
            "200/200 [==============================] - 138s 688ms/step - loss: 1.6359 - acc: 0.4371 - val_loss: 1.6958 - val_acc: 0.4987\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.69582, saving model to ./model/CamVid_model_v1.hdf5\n",
            "Epoch 2/30\n",
            "200/200 [==============================] - 135s 673ms/step - loss: 1.1761 - acc: 0.5924 - val_loss: 1.0950 - val_acc: 0.5808\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.69582 to 1.09502, saving model to ./model/CamVid_model_v1.hdf5\n",
            "Epoch 3/30\n",
            "200/200 [==============================] - 134s 668ms/step - loss: 0.9285 - acc: 0.6748 - val_loss: 1.3794 - val_acc: 0.6030\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.09502\n",
            "Epoch 4/30\n",
            "200/200 [==============================] - 133s 667ms/step - loss: 0.8422 - acc: 0.6995 - val_loss: 1.4845 - val_acc: 0.5795\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.09502\n",
            "Epoch 5/30\n",
            "200/200 [==============================] - 134s 668ms/step - loss: 0.7697 - acc: 0.7339 - val_loss: 1.2216 - val_acc: 0.6568\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.09502\n",
            "Epoch 6/30\n",
            "200/200 [==============================] - 134s 668ms/step - loss: 0.6887 - acc: 0.7564 - val_loss: 1.0242 - val_acc: 0.6469\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.09502 to 1.02423, saving model to ./model/CamVid_model_v1.hdf5\n",
            "Epoch 7/30\n",
            "200/200 [==============================] - 134s 668ms/step - loss: 0.6601 - acc: 0.7756 - val_loss: 1.7210 - val_acc: 0.6052\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.02423\n",
            "Epoch 8/30\n",
            "200/200 [==============================] - 133s 667ms/step - loss: 0.6707 - acc: 0.7730 - val_loss: 1.3282 - val_acc: 0.7113\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.02423\n",
            "Epoch 9/30\n",
            "200/200 [==============================] - 133s 666ms/step - loss: 0.6424 - acc: 0.7855 - val_loss: 1.6033 - val_acc: 0.6392\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.02423\n",
            "Epoch 10/30\n",
            "200/200 [==============================] - 133s 667ms/step - loss: 0.5449 - acc: 0.8094 - val_loss: 1.9488 - val_acc: 0.6166\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.02423\n",
            "Epoch 11/30\n",
            "200/200 [==============================] - 133s 665ms/step - loss: 0.4900 - acc: 0.8258 - val_loss: 1.3138 - val_acc: 0.6748\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.02423\n",
            "Epoch 12/30\n",
            "200/200 [==============================] - 133s 665ms/step - loss: 0.5092 - acc: 0.8235 - val_loss: 0.8824 - val_acc: 0.7375\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.02423 to 0.88237, saving model to ./model/CamVid_model_v1.hdf5\n",
            "Epoch 13/30\n",
            "166/200 [=======================>......] - ETA: 22s - loss: 0.4641 - acc: 0.8359"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yx5vctCk_m8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}